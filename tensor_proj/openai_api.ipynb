{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876eee3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenvNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n"
     ]
    }
   ],
   "source": [
    "# pip install python-dotenv   # í™•ì¥ìê°€ envì¸ íŒŒì¼ ì½ì–´ì„œ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d89777a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7ac0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')    # .env íŒŒì¼ì—ì„œ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì½ê¸°\n",
    "\n",
    "# print('Key : ', OPENAI_API_KEY)\n",
    "# API í‚¤ë¥¼ ì ˆëŒ€ Publicì— ë…¸ì¶œí•˜ì§€ ë§ ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1a6b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c9c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4.1',\n",
    "    input = 'ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì˜ ë‹¤ìŠ¤ ë² ì´ë”ì˜ ì—­í• ì— ëŒ€í•´ í•œ ì¤„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8b30eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹¤ìŠ¤ ë² ì´ë”ëŠ” ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì—ì„œ ì œêµ­ì˜ ì•”í‘ êµ°ì£¼ë¡œ, ì˜¤ë¹„ì™„ ì¼€ë…¸ë¹„ì˜ ì œì ì•„ë‚˜í‚¨ ìŠ¤ì¹´ì´ì›Œì»¤ì—ì„œ íƒ€ë½í•œ ì¡´ì¬ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text    # ê°ì²´ í˜•ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7696ab8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŠ¤ ë² ì´ë”ëŠ” íƒ€ë½í•œ ì œë‹¤ì´ ê¸°ì‚¬ë¡œ, ì€í•˜ ì œêµ­ì˜ ìƒì§•ì ì¸ ì•…ë‹¹ì´ì ë£¨í¬ ìŠ¤ì¹´ì´ì›Œì»¤ì˜ ì•„ë²„ì§€ë¡œì„œ ì´ì•¼ê¸°ì˜ í•µì‹¬ ê°ˆë“±ê³¼ ë¹„ê·¹ì„ ì´ë„ëŠ” ì¸ë¬¼ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4.1',\n",
    "    instructions = 'ë‹¹ì‹ ì€ ì˜í™” í‰ë¡ ê°€ì…ë‹ˆë‹¤.', # ì—­í• ì— ëŒ€í•œ ê°€ì´ë“œ\n",
    "    input = 'ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì˜ ë‹¤ìŠ¤ ë² ì´ë”ì˜ ì—­í• ì— ëŒ€í•´ í•œ ì¤„ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.'    # í”„ë¡¬í”„íŠ¸\n",
    ")\n",
    "print(response.output_text)  # ë¬¸ìì—´ í˜•ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655514f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ì€ íŠ¹ë³„íˆ ì–´ë–¤ ì¢…ë¥˜ì˜ ìŒì‹ì´ ë•¡ê¸°ë‚˜ìš”? í•œì‹, ì¼ì‹, ì¤‘ì‹, ì–‘ì‹ ì¤‘ì—ì„œ ê³ ë¯¼í•˜ê³  ê³„ì‹ ê°€ìš”, ì•„ë‹ˆë©´ ê°„ë‹¨í•˜ê²Œ ì§‘ì—ì„œ í•´ ë¨¹ì„ ìˆ˜ ìˆëŠ” ë©”ë‰´ê°€ í•„ìš”í•˜ì‹ ê°€ìš”?\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´ì„œ:\n",
      "\n",
      "- **í•œì‹**: ê¹€ì¹˜ì°Œê°œ, ë¶ˆê³ ê¸°, ë¹„ë¹”ë°¥, ê¹€ë°¥\n",
      "- **ì¼ì‹**: ê°€ì¸ ë™, ë¼ë©˜, ì´ˆë°¥, ì˜¤ì½”ë…¸ë¯¸ì•¼ë¼\n",
      "- **ì¤‘ì‹**: ì§œì¥ë©´, ì§¬ë½•, íƒ•ìˆ˜ìœ¡, ë§ˆíŒŒë‘ë¶€\n",
      "- **ì–‘ì‹**: íŒŒìŠ¤íƒ€, ìƒëŸ¬ë“œ, ìŠ¤í…Œì´í¬, í”¼ì\n",
      "\n",
      "í˜¹ì‹œ ì˜¤ëŠ˜ ë‚ ì”¨ë‚˜ ê¸°ë¶„ì— ë”°ë¼ ë” ì–´ìš¸ë¦¬ëŠ” ìŒì‹ì´ ìˆì„ ìˆ˜ë„ ìˆì–´ìš”. ìŒ€ìŒ€í•˜ë©´ ë”°ëœ»í•œ ì°Œê°œë¥˜ë‚˜ êµ­ë¬¼ ìŒì‹, ë”ìš´ ë‚ ì—” ì‹œì›í•œ ëƒ‰ë©´ì´ë‚˜ ìƒëŸ¬ë“œë„ ì¢‹ì£ !\n",
      "\n",
      "ì–´ë–¤ ë©”ë‰´ê°€ ëŒë¦¬ëŠ”ì§€, ì•„ë‹ˆë©´ ì§‘ì— ì¬ë£Œê°€ ìˆëŠ”ì§€ ì•Œë ¤ì£¼ì‹œë©´ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model = 'gpt-4.1',\n",
    "    input = [\n",
    "        {\n",
    "            'role' : 'developer',\n",
    "            'content' : 'ìŒì‹ì— ëŒ€í•œ ì´ì•¼ê¸° í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•´.'\n",
    "        },\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : 'ì˜¤ëŠ˜ì€ ë¬´ì—‡ì„ ë¨¹ì„ê¹Œ?'\n",
    "        }]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6305c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model = 'gpt-4.1',\n",
    "    messages= [\n",
    "        {\n",
    "            'role' : 'user',\n",
    "            'content' : 'ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.'\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fe2f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆëŠ” ë¨¼ ìš°ì£¼ì˜ ì€í•˜ê³„ì—ì„œ ì„ ê³¼ ì•…ì˜ ëŒ€ê²°, ì œë‹¤ì´ì™€ ì‹œìŠ¤, ê·¸ë¦¬ê³  ê°€ì¡±ì˜ ì´ì•¼ê¸°ë¥¼ ê·¸ë¦° SF íŒíƒ€ì§€ ì˜í™” ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict(completion.choices[0])  # ê°ì²´ í˜•ì‹\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71f6258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì…ë ¥í•˜ì‹  í”„ë¡¬í”„íŠ¸] :  ì¹´ë ˆê°€ë£¨ 5Tì— íƒ„ìˆ˜í™”ë¬¼ì´ ë§ì´ ë“¤ì–´ê°ˆê¹Œ?\n",
      "ì¢‹ì€ ì§ˆë¬¸ì…ë‹ˆë‹¤! ì¹´ë ˆê°€ë£¨(ì¼ë°˜ì ìœ¼ë¡œ ì‹œíŒë˜ëŠ” ë¶„ë§ ì¹´ë ˆ ê¸°ì¤€)ì— ë“¤ì–´ìˆëŠ” íƒ„ìˆ˜í™”ë¬¼ í•¨ëŸ‰ì€ ì œí’ˆë§ˆë‹¤ ì¡°ê¸ˆ ë‹¤ë¥´ì§€ë§Œ, í‰ê· ì ìœ¼ë¡œ ëŒ€ëµ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "### **ì¼ë°˜ì ì¸ ì¹´ë ˆê°€ë£¨ ì˜ì–‘ì„±ë¶„ (100g ê¸°ì¤€)**\n",
      "- **íƒ„ìˆ˜í™”ë¬¼**: ì•½ 50~70g  \n",
      "- **1T (í…Œì´ë¸”ìŠ¤í‘¼, ì•½ 8g ê¸°ì¤€)**  \n",
      "  - 1T ë‹¹ íƒ„ìˆ˜í™”ë¬¼: ì•½ 4~5.6g  \n",
      "- **5Të¼ë©´?**\n",
      "  - 5T(ì•½ 40g) Ã— 50~70% = íƒ„ìˆ˜í™”ë¬¼ ì•½ 20~28g\n",
      "\n",
      "#### **ì¹´ë ˆê°€ë£¨ 5T(40g) ê¸°ì¤€ íƒ„ìˆ˜í™”ë¬¼**\n",
      "- **ì•½ 20~28g** ì •ë„\n",
      "\n",
      "---\n",
      "\n",
      "### ì¶”ê°€ ì„¤ëª…\n",
      "- ì‹œíŒë˜ëŠ” ë¶„ë§ ì¹´ë ˆê°€ë£¨ì—ëŠ” ë°€ê°€ë£¨, ê°ìì „ë¶„ ë“± íƒ„ìˆ˜í™”ë¬¼ì´ í¬í•¨ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ìƒê°ë³´ë‹¤ íƒ„ìˆ˜í™”ë¬¼ì´ ë§ìŠµë‹ˆë‹¤.\n",
      "- íŠ¹íˆ ì‹œíŒë˜ëŠ” \"ì¹´ë ˆ ë¸”ë¡\" ì œí’ˆ(ê³ í˜• ì¹´ë ˆ)ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë°€ê°€ë£¨ ë¹„ìœ¨ì´ ë†’ì•„ì„œ, ë¶„ë§ ì¹´ë ˆê°€ë£¨ë³´ë‹¤ ë” ë†’ì€ íƒ„ìˆ˜í™”ë¬¼ í•¨ëŸ‰ì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### **ê²°ë¡ **\n",
      "ë„¤, **ì¹´ë ˆê°€ë£¨ 5Tì—ëŠ” íƒ„ìˆ˜í™”ë¬¼ì´ ê½¤ ë§ì´ ë“¤ì–´ ìˆìŠµë‹ˆë‹¤.**  \n",
      "ì €íƒ„ìˆ˜í™”ë¬¼ ì‹ë‹¨ì„ í•˜ì‹ ë‹¤ë©´, ì¹´ë ˆê°€ë£¨ ì–‘ì„ ì¡°ì ˆí•˜ê±°ë‚˜, ì €íƒ„ìˆ˜í™”ë¬¼ ë ˆì‹œí”¼ë¥¼ í™œìš©í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì¶”ê°€ ì§ˆë¬¸ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# Pythonì„ í™œìš©í•œ OpenAI API í˜¸ì¶œ\n",
    "# ì½˜ì†”ì—ì„œ ì‚¬ìš©ì ì…ë ¥(ì§ˆë¬¸, í”„ë¡¬í”„íŠ¸)ë¥¼ ë°›ê³  ì‘ë‹µ ì²˜ë¦¬í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ ë´…ì‹œë‹¤.\n",
    "question= input('ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ')\n",
    "response = client.responses.create(\n",
    "    model = 'gpt-4.1',\n",
    "    instructions = 'ë‹¹ì‹ ì€ ì˜ì‚¬ì…ë‹ˆë‹¤.',\n",
    "    input = question\n",
    ")\n",
    "print('[ì…ë ¥í•˜ì‹  í”„ë¡¬í”„íŠ¸] : ', question)\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6c90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš°ë¦¬ ì¹œêµ¬~ ì˜¤ëšœê¸° ë§¤ìš´ë§› ì¹´ë ˆê°€ë£¨ê°€ ê¶ê¸ˆí–ˆêµ¬ë‚˜! ì„ ìƒë‹˜ì´ ì‰½ê²Œ ì•Œë ¤ì¤„ê²Œ!\n",
      "\n",
      "**ì˜¤ëšœê¸° ë§¤ìš´ë§› ì¹´ë ˆê°€ë£¨**ëŠ” ë³´í†µ 100gì— ì•½ 70g ì •ë„ì˜ íƒ„ìˆ˜í™”ë¬¼ì´ ë“¤ì–´ ìˆì–´.  \n",
      "í•œ í°ìˆ (1T, í…Œì´ë¸”ìŠ¤í‘¼)ì€ ì•½ 7~8g ì •ë„ ë˜ë‹ˆê¹Œ, 5TëŠ” 35~40gì´ì•¼.\n",
      "\n",
      "ê·¸ë˜ì„œ **5T(ì•½ 35~40g)**ì—ëŠ” **ì•½ 24~28g**ì˜ íƒ„ìˆ˜í™”ë¬¼ì´ ë“¤ì–´ ìˆì–´!\n",
      "\n",
      "ìˆ«ìê°€ ì¡°ê¸ˆ ì–´ë µì§€?  \n",
      "ì¹´ë ˆê°€ë£¨ 5ìˆŸê°€ë½ì„ ë¨¹ìœ¼ë©´, ìš°ë¦¬ ëª¸ì— ì¢‹ì€ í˜ì„ ì£¼ëŠ” íƒ„ìˆ˜í™”ë¬¼ì´ ì°°ì¹µ! í•˜ê³  ë“¤ì–´ì˜¨ë‹¤ê³  ìƒê°í•˜ë©´ ë¼~  \n",
      "í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ê±° ìˆë‹ˆ? ^_^\n"
     ]
    }
   ],
   "source": [
    "# ê°•ì‚¬ë‹˜ ì½”ë“œ\n",
    "user_input = input('ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”? ì§ˆë¬¸ì„ ë‚¨ê²¨ì£¼ì„¸ìš”! ')\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input = [\n",
    "        {\n",
    "            'role': 'developer',\n",
    "            'content': 'ë„ˆëŠ” ìœ ì¹˜ì› ì„ ìƒë‹˜ì´ì•¼. ì•„ì´ë“¤ì„ ëŒ€í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì´ì•¼ê¸°í•´ì¤˜.'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_input\n",
    "}\n",
    "     ]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dd3a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eced5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "        \"latitude\": {\"type\": \"number\"},\n",
    "        \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ecfdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages = [{ 'role' : 'user', 'content' : 'ì˜¤ëŠ˜ íŒŒë¦¬ ë‚ ì”¨ ì–´ë•Œ?' }]\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œí•˜ëŠ” ê¸°ëŠ¥\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fea74b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
       " 'call_id': 'call_lEUkT1A6pPeA0KwbJyaXTW40',\n",
       " 'name': 'get_weather',\n",
       " 'type': 'function_call',\n",
       " 'id': 'fc_685ca0a877dc819bba340d83a60a64ce0baa13016881d1e3',\n",
       " 'status': 'completed'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba6abef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.6\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "result = get_weather(args['latitude'], args['longitude'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d0a4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages.append(tool_call)\n",
    "input_messages.append({\n",
    "    'type' : 'function_call_output',\n",
    "    'call_id' : tool_call.call_id, # call_idë¡œ ìˆ˜ì •\n",
    "    'output' : str(result)  # ë¬¸ìì—´ ë°˜í™˜\n",
    "})\n",
    "\n",
    "# ìµœì¢… ì‘ë‹µ\n",
    "response2 = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "733f7663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ íŒŒë¦¬ì˜ ê¸°ì˜¨ì€ ì•½ 21.6Â°Cë¡œ, ì˜¨í™”í•˜ê³  ì¾Œì í•œ ë‚ ì”¨ì…ë‹ˆë‹¤. ì™¸ì¶œí•˜ê¸° ì¢‹ì€ ë‚ ì”¨ì˜ˆìš”!\n"
     ]
    }
   ],
   "source": [
    "print(response2.output_text)  # ìµœì¢… ì‘ë‹µ ì¶œë ¥\n",
    "\n",
    "# tool_call.call_id ìˆ˜ì • í›„, ìœ„ì—ì„œë¶€í„° ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e91700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.basic_tools import calculate_age, convert_currency, calculate_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cba01c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_age\",\n",
    "        \"description\": \"ì…ë ¥ëœ ìƒë…„ì›”ì¼(YYYY-mm-dd)ë¡œ ë§Œ ë‚˜ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"birthdate\": {\"type\": \"string\", \"description\": \"ìƒë…„ì›”ì¼, í˜•ì‹:YYYY-MM-DD\"}\n",
    "            },\n",
    "        \"required\": [\"birthdate\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"convert_currency\",\n",
    "        \"description\": \"ì…ë ¥ëœ ë‹¬ëŸ¬(USD)ë¥¼ ì›í™”(KRW)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"amount\": {\"type\": \"number\", \"description\": \"ë‹¬ëŸ¬(USD) ê¸ˆì•¡\"}\n",
    "            },\n",
    "        \"required\": [\"amount\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_bmi\",\n",
    "        \"description\": \"í‚¤(cm), ëª¸ë¬´ê²Œ(kg) ì •ë³´ë¥¼ ë°›ì•„ì„œ BMIë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"height\": {\"type\": \"number\", \"description\": \"í‚¤(cm)\"},\n",
    "                \"weight\": {\"type\": \"number\", \"description\": \"ëª¸ë¬´ê²Œ(cm)\"}\n",
    "            },\n",
    "        \"required\": [\"height\", \"weight\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b675c6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_jtunByq88eg6rL02FE7Asr77', name='calculate_age', type='function_call', id='fc_685cc6e11b9081999c2afde2e18478410d51e37a36df088c', status='completed'), ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_WubQGcuburuyCkAeIGT51qSP', name='convert_currency', type='function_call', id='fc_685cc6e14024819992ecddb89d96a11b0d51e37a36df088c', status='completed'), ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_QzfcQv3rz4DNxgLwhzaI2Ad7', name='calculate_bmi', type='function_call', id='fc_685cc6e156208199b5b5a22ff3c04a8f0d51e37a36df088c', status='completed')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\": \"ë‚´ ìƒì¼ì€ 1990-01-01 ì´ê³ , 100 ë‹¬ëŸ¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° ì›í™”ë¡œ ë³€í™˜í•´ì¤˜, ê·¸ë¦¬ê³  ë‚´ í‚¤ëŠ” 190cm ì´ê³  ëª¸ë¬´ê²ŒëŠ” 50kg ì´ì•¼ BMI ì ìˆ˜ë¥¼ ì•Œë ¤ì¤˜\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=fn_tools\n",
    ")\n",
    "\n",
    "print(response.output)\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "578e5abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_jtunByq88eg6rL02FE7Asr77', name='calculate_age', type='function_call', id='fc_685cc6e11b9081999c2afde2e18478410d51e37a36df088c', status='completed')\n",
      "ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_WubQGcuburuyCkAeIGT51qSP', name='convert_currency', type='function_call', id='fc_685cc6e14024819992ecddb89d96a11b0d51e37a36df088c', status='completed')\n",
      "ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_QzfcQv3rz4DNxgLwhzaI2Ad7', name='calculate_bmi', type='function_call', id='fc_685cc6e156208199b5b5a22ff3c04a8f0d51e37a36df088c', status='completed')\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0])\n",
    "print(response.output[1])\n",
    "print(response.output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8243154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜¸ì¶œ ë„êµ¬:calculate_age\n",
      "ë§¤ê°œë³€ìˆ˜: {\"birthdate\":\"1990-01-01\"}\n",
      "í˜¸ì¶œ ë„êµ¬:convert_currency\n",
      "ë§¤ê°œë³€ìˆ˜: {\"amount\":100}\n",
      "í˜¸ì¶œ ë„êµ¬:calculate_bmi\n",
      "ë§¤ê°œë³€ìˆ˜: {\"height\":190,\"weight\":50}\n",
      "[{'role': 'user', 'content': 'ë‚´ ìƒì¼ì€ 1990-01-01 ì´ê³ , 100 ë‹¬ëŸ¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° ì›í™”ë¡œ ë³€í™˜í•´ì¤˜, ê·¸ë¦¬ê³  ë‚´ í‚¤ëŠ” 190cm ì´ê³  ëª¸ë¬´ê²ŒëŠ” 50kg ì´ì•¼ BMI ì ìˆ˜ë¥¼ ì•Œë ¤ì¤˜'}, ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_jtunByq88eg6rL02FE7Asr77', name='calculate_age', type='function_call', id='fc_685cc6e11b9081999c2afde2e18478410d51e37a36df088c', status='completed'), {'type': 'function_call_output', 'call_id': 'call_jtunByq88eg6rL02FE7Asr77', 'output': '35'}, ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_WubQGcuburuyCkAeIGT51qSP', name='convert_currency', type='function_call', id='fc_685cc6e14024819992ecddb89d96a11b0d51e37a36df088c', status='completed'), {'type': 'function_call_output', 'call_id': 'call_WubQGcuburuyCkAeIGT51qSP', 'output': '133000'}, ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_QzfcQv3rz4DNxgLwhzaI2Ad7', name='calculate_bmi', type='function_call', id='fc_685cc6e156208199b5b5a22ff3c04a8f0d51e37a36df088c', status='completed'), {'type': 'function_call_output', 'call_id': 'call_QzfcQv3rz4DNxgLwhzaI2Ad7', 'output': '13.85'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "if response.output :\n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type == 'function_call':\n",
    "            if tool_call.name == 'calculate_age':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = calculate_age(args['birthdate'])\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "            \n",
    "            \n",
    "            if tool_call.name == 'convert_currency':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = convert_currency(args['amount'])\n",
    "\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "            \n",
    "            if tool_call.name == 'calculate_bmi':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = calculate_bmi(args['height'],args['weight'])\n",
    "\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "\n",
    "print(input_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad0868e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš”ì²­í•˜ì‹  ì •ë³´ë¥¼ ì •ë¦¬í•´ë“œë¦¬ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. ë§Œ ë‚˜ì´: 35ì„¸\n",
      "2. 100ë‹¬ëŸ¬ë¥¼ ì›í™”ë¡œ í™˜ì‚°: ì•½ 133,000ì›\n",
      "3. BMI(190cm, 50kg): 13.85\n",
      "\n",
      "ì¶”ê°€ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "response_msg = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=fn_tools\n",
    ")\n",
    "\n",
    "print(response_msg.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031620e",
   "metadata": {},
   "source": [
    "### File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc41bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "#from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    # í•µì‹¬\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c929eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-Sfx4Uq5MVbpT2UwYGDeEEL\n"
     ]
    }
   ],
   "source": [
    "# ë“±ë¡, ì•„ì´ë”” ê°’ ë°˜í™˜\n",
    "file_id = create_file(client, './howto-sockets.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d18c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_685cc777a6f08191b92de16acc99b6ae\n"
     ]
    }
   ],
   "source": [
    "# ìŠ¤í† ì–´ ìƒì„±\n",
    "vector_store = client.vector_stores.create(\n",
    "    name='knowledge_base'\n",
    ")\n",
    "\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf0d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFile(id='file-Sfx4Uq5MVbpT2UwYGDeEEL', created_at=1750910841, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_685cc777a6f08191b92de16acc99b6ae', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìƒˆë¡œìš´ íŒŒì¼ ë“±ë¡\n",
    "client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d84ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-Sfx4Uq5MVbpT2UwYGDeEEL', created_at=1750910841, last_error=None, object='vector_store.file', status='completed', usage_bytes=29112, vector_store_id='vs_685cc777a6f08191b92de16acc99b6ae', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-Sfx4Uq5MVbpT2UwYGDeEEL', last_id='file-Sfx4Uq5MVbpT2UwYGDeEEL')\n"
     ]
    }
   ],
   "source": [
    "# ì–´ë–¤ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸\n",
    "result_list = client.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33ac9089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_685cd0c4931c819985ee777f7ddfbaba0dd19cdc18a9527a', created_at=1750913220.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_685cd0c51754819984a88848523d006c0dd19cdc18a9527a', content=[ResponseOutputText(annotations=[], text=\"íŒŒì´ì¬ì—ì„œ ì†Œì¼“(socket)ì„ ë§Œë“œëŠ” ê¸°ë³¸ì ì¸ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n### 1. ì†Œì¼“ ëª¨ë“ˆ ì„í¬íŠ¸\\n```python\\nimport socket\\n```\\n\\n### 2. ì†Œì¼“ ê°ì²´ ìƒì„±\\n```python\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n```\\n- `socket.AF_INET`: IPv4 ì‚¬ìš©  \\n- `socket.SOCK_STREAM`: TCP ì†Œì¼“(ìŠ¤íŠ¸ë¦¼ ì†Œì¼“)\\n\\n### 3. ì„œë²„(ì˜ˆì‹œ)\\n#### ë°”ì¸ë“œ(bind) & ë¦¬ìŠ¨(listen)\\n```python\\ns.bind(('127.0.0.1', 12345))  # IP ì£¼ì†Œì™€ í¬íŠ¸ ë°”ì¸ë“œ\\ns.listen(1)                   # ìµœëŒ€ 1ê°œì˜ í´ë¼ì´ì–¸íŠ¸ ëŒ€ê¸°\\n```\\n\\n#### í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìˆ˜ë½ & ë°ì´í„° ì†¡ìˆ˜ì‹ \\n```python\\nconn, addr = s.accept()       # ì—°ê²° ìˆ˜ë½\\ndata = conn.recv(1024)        # ë°ì´í„° ìˆ˜ì‹  (1024ë°”ì´íŠ¸)\\nconn.sendall(b'Hello, client')# ë°ì´í„° ì „ì†¡\\nconn.close()                  # ì—°ê²° ì¢…ë£Œ\\n```\\n\\n### 4. í´ë¼ì´ì–¸íŠ¸(ì˜ˆì‹œ)\\n```python\\ns.connect(('127.0.0.1', 12345)) # ì„œë²„ì— ì—°ê²°\\ns.sendall(b'Hello, server')     # ë°ì´í„° ì „ì†¡\\ndata = s.recv(1024)             # ë°ì´í„° ìˆ˜ì‹ \\ns.close()                       # ì—°ê²° ì¢…ë£Œ\\n```\\n\\n---\\n\\nìš”ì•½í•˜ìë©´,  \\n1. `socket.socket()`ìœ¼ë¡œ ì†Œì¼“ ê°ì²´ë¥¼ ë§Œë“ ë‹¤.  \\n2. ì„œë²„ë¼ë©´ `bind()`, `listen()`, `accept()` ê³¼ì •ì„ ê±°ì¹œë‹¤.  \\n3. í´ë¼ì´ì–¸íŠ¸ë¼ë©´ `connect()`ë¡œ ì„œë²„ì— ì—°ê²°í•œë‹¤.  \\n4. `send()`ì™€ `recv()`ë¥¼ ì´ìš©í•´ì„œ ë°ì´í„° ì£¼ê³ ë°›ëŠ”ë‹¤.  \\n5. ì‘ì—…ì´ ëë‚˜ë©´ `close()`ë¡œ ì†Œì¼“ì„ ë‹«ëŠ”ë‹¤.\\n\\në” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\", type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FileSearchTool(type='file_search', vector_store_ids=['vs_685cc777a6f08191b92de16acc99b6ae'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=813, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=424, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1237), user=None, max_tool_calls=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='íŒŒì´ì¬ ì½”ë“œë¡œ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜.',\n",
    "    tools=[{\n",
    "        'type' : 'file_search',\n",
    "        'vector_store_ids' : [vector_store.id]\n",
    "    }],\n",
    "    tool_choice='auto'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "243b2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'resp_685cd035497881998ad324e88ae849da06769eb1f7823ac2', 'created_at': 1750913077.0, 'error': None, 'incomplete_details': None, 'instructions': None, 'metadata': {}, 'model': 'gpt-4.1-2025-04-14', 'object': 'response', 'output': [ResponseOutputMessage(id='msg_685cd035d7508199b60f989deda1ad2806769eb1f7823ac2', content=[ResponseOutputText(annotations=[], text=\"íŒŒì´ì¬ì—ì„œ ì†Œì¼“(socket)ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\\n\\n1. ì†Œì¼“ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸°  \\në¨¼ì €, íŒŒì´ì¬ì˜ ì†Œì¼“ í”„ë¡œê·¸ë˜ë°ì„ ìœ„í•´ socket ëª¨ë“ˆì„ import í•´ì•¼ í•©ë‹ˆë‹¤.\\n\\n```python\\nimport socket\\n```\\n\\n2. ì†Œì¼“ ê°ì²´ ìƒì„±  \\nsocket.socket()ì„ ì‚¬ìš©í•´ì„œ ì†Œì¼“ ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤.  \\nì˜ˆë¥¼ ë“¤ì–´, IPv4ì™€ TCPë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:\\n\\n```python\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n```\\n- `AF_INET` : IPv4 ì‚¬ìš©\\n- `SOCK_STREAM` : TCP ì‚¬ìš©\\n\\n3. ì„œë²„ ì†Œì¼“ ì˜ˆì‹œ  \\nê°„ë‹¨í•œ ì„œë²„ ì†Œì¼“ ì½”ë“œ ì˜ˆì‹œì…ë‹ˆë‹¤.\\n\\n```python\\nimport socket\\n\\n# 1. ì†Œì¼“ ìƒì„±\\nserver_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n# 2. ì£¼ì†Œì™€ í¬íŠ¸ ë°”ì¸ë”©\\nserver_socket.bind(('localhost', 9999))\\n# 3. í´ë¼ì´ì–¸íŠ¸ ì ‘ì† ëŒ€ê¸°\\nserver_socket.listen()\\nprint('ì„œë²„ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.')\\n\\n# 4. í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìˆ˜ë½\\nclient_socket, addr = server_socket.accept()\\nprint('ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸:', addr)\\n\\n# 5. ë°ì´í„° ì†¡ìˆ˜ì‹ \\ndata = client_socket.recv(1024)\\nprint('ë°›ì€ ë°ì´í„°:', data.decode())\\n\\nclient_socket.sendall('Hello Client!'.encode())\\n\\n# 6. ì†Œì¼“ ì¢…ë£Œ\\nclient_socket.close()\\nserver_socket.close()\\n```\\n\\n4. í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“ ì˜ˆì‹œ  \\nê°„ë‹¨í•œ í´ë¼ì´ì–¸íŠ¸ ì½”ë“œ ì˜ˆì‹œì…ë‹ˆë‹¤.\\n\\n```python\\nimport socket\\n\\n# 1. ì†Œì¼“ ìƒì„±\\nclient_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n# 2. ì„œë²„ì— ì—°ê²°\\nclient_socket.connect(('localhost', 9999))\\n# 3. ë°ì´í„° ì†¡ìˆ˜ì‹ \\nclient_socket.sendall('Hello Server!'.encode())\\n\\ndata = client_socket.recv(1024)\\nprint('ë°›ì€ ë°ì´í„°:', data.decode())\\n# 4. ì†Œì¼“ ì¢…ë£Œ\\nclient_socket.close()\\n```\\n\\nì´ë ‡ê²Œ ì†Œì¼“ì„ ìƒì„±í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!  \\nê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì¶”ê°€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.\", type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], 'parallel_tool_calls': True, 'temperature': 1.0, 'tool_choice': 'auto', 'tools': [FileSearchTool(type='file_search', vector_store_ids=['vs_685cc777a6f08191b92de16acc99b6ae'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], 'top_p': 1.0, 'background': False, 'max_output_tokens': None, 'previous_response_id': None, 'prompt': None, 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None), 'service_tier': 'default', 'status': 'completed', 'text': ResponseTextConfig(format=ResponseFormatText(type='text')), 'truncation': 'disabled', 'usage': ResponseUsage(input_tokens=813, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=465, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1278), 'user': None, 'max_tool_calls': None, 'store': True}\n"
     ]
    }
   ],
   "source": [
    "print(dict(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d5c43f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (2.0.2)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (2.3.0)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (11.2.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (5.29.5)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-20.0.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (2.32.4)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (4.14.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.44.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.25.1-cp39-cp39-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\project\\tensor_proj\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.1/10.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.7/10.1 MB 11.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.3/10.1 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.1 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 2.4/6.9 MB 12.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Downloading narwhals-1.44.0-py3-none-any.whl (365 kB)\n",
      "Downloading pyarrow-20.0.0-cp39-cp39-win_amd64.whl (25.8 MB)\n",
      "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.1/25.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 4.7/25.8 MB 11.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/25.8 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 9.7/25.8 MB 11.8 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.1/25.8 MB 11.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.4/25.8 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.0/25.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.4/25.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.0/25.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.4/25.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.8/25.8 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.25.1-cp39-cp39-win_amd64.whl (231 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, rpds-py, pyarrow, narwhals, jinja2, click, cachetools, blinker, attrs, referencing, pydeck, gitdb, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   ----------------------------------------  0/20 [watchdog]\n",
      "   ----------------------------------------  0/20 [watchdog]\n",
      "   ----------------------------------------  0/20 [watchdog]\n",
      "   ----------------------------------------  0/20 [watchdog]\n",
      "   ----------------------------------------  0/20 [watchdog]\n",
      "   -- -------------------------------------  1/20 [toml]\n",
      "   ---- -----------------------------------  2/20 [tenacity]\n",
      "   ---- -----------------------------------  2/20 [tenacity]\n",
      "   ------ ---------------------------------  3/20 [smmap]\n",
      "   -------- -------------------------------  4/20 [rpds-py]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ---------- -----------------------------  5/20 [pyarrow]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   ------------ ---------------------------  6/20 [narwhals]\n",
      "   -------------- -------------------------  7/20 [jinja2]\n",
      "   -------------- -------------------------  7/20 [jinja2]\n",
      "   -------------- -------------------------  7/20 [jinja2]\n",
      "   -------------- -------------------------  7/20 [jinja2]\n",
      "   -------------- -------------------------  7/20 [jinja2]\n",
      "   ---------------- -----------------------  8/20 [click]\n",
      "   ---------------- -----------------------  8/20 [click]\n",
      "   ---------------- -----------------------  8/20 [click]\n",
      "   ------------------ ---------------------  9/20 [cachetools]\n",
      "   -------------------- ------------------- 10/20 [blinker]\n",
      "   ---------------------- ----------------- 11/20 [attrs]\n",
      "   ---------------------- ----------------- 11/20 [attrs]\n",
      "   ---------------------- ----------------- 11/20 [attrs]\n",
      "   ------------------------ --------------- 12/20 [referencing]\n",
      "   ------------------------ --------------- 12/20 [referencing]\n",
      "   -------------------------- ------------- 13/20 [pydeck]\n",
      "   -------------------------- ------------- 13/20 [pydeck]\n",
      "   -------------------------- ------------- 13/20 [pydeck]\n",
      "   -------------------------- ------------- 13/20 [pydeck]\n",
      "   -------------------------- ------------- 13/20 [pydeck]\n",
      "   -------------------------- ------------- 13/20 [pydeck]\n",
      "   ---------------------------- ----------- 14/20 [gitdb]\n",
      "   ---------------------------- ----------- 14/20 [gitdb]\n",
      "   ---------------------------- ----------- 14/20 [gitdb]\n",
      "   ---------------------------- ----------- 14/20 [gitdb]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   -------------------------------- ------- 16/20 [gitpython]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ---------------------------------- ----- 17/20 [jsonschema]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   ------------------------------------ --- 18/20 [altair]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   -------------------------------------- - 19/20 [streamlit]\n",
      "   ---------------------------------------- 20/20 [streamlit]\n",
      "\n",
      "Successfully installed altair-5.5.0 attrs-25.3.0 blinker-1.9.0 cachetools-6.1.0 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 jinja2-3.1.6 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 narwhals-1.44.0 pyarrow-20.0.0 pydeck-0.9.1 referencing-0.36.2 rpds-py-0.25.1 smmap-5.0.2 streamlit-1.46.0 tenacity-9.1.2 toml-0.10.2 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

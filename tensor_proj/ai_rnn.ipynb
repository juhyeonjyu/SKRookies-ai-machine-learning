{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30be2cc9",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeeaac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 샘플 텍스트 데이터\n",
    "data = \"\"\"나는 오늘 기분이 좋아.\n",
    "나는 내일도 기분이 좋을 거야.\n",
    "기분이 좋은 날엔 춤을 추고 싶어.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138709bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 토큰화: 텍스트 데이터를 숫자로 변환\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data.split('\\n'))\n",
    "sequences = tokenizer.texts_to_sequences(data.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff129435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 단어 인덱스 확인\n",
    "word_index = tokenizer.word_index\n",
    "print(\"단어 인덱스:\", word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 시퀀스를 학습 데이터로 변환\n",
    "input_sequences = []\n",
    "for sequence in sequences:\n",
    "    for i in range(1, len(sequence)):\n",
    "        input_sequences.append(sequence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd871fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 패딩 처리\n",
    "max_len = max(len(x) for x in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b11045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 입력(X)과 출력(y) 분리\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298f6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197047a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 출력(y)을 원-핫 인코딩\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(word_index) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 모델 정의\n",
    "rnn_model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1,\n",
    "              output_dim=10,\n",
    "              input_length=max_len - 1), # 임베딩 층\n",
    "    SimpleRNN(64, return_sequences=False), # RNN 층\n",
    "    Dense(len(word_index) + 1,\n",
    "          activation='softmax') # 출력 층\n",
    "])\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "rnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "rnn_model.fit(X, y, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 정의\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1,\n",
    "              output_dim=10,\n",
    "              input_length=max_len - 1), # 임베딩 층\n",
    "    LSTM(64, return_sequences=False), # LSTM 층\n",
    "    Dense(len(word_index) + 1,\n",
    "          activation='softmax') # 출력 층\n",
    "])\n",
    "# 모델 컴파일 및 학습\n",
    "lstm_model.compile(loss='categorical_crossentropy', \n",
    "                   optimizer='adam', \n",
    "                   metrics=['accuracy'])\n",
    "lstm_model.fit(X, y, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc587846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU 모델 정의\n",
    "gru_model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1,output_dim=10,input_length=max_len - 1), # 임베딩 층\n",
    "    GRU(64, return_sequences=False), # GRU 층\n",
    "    Dense(len(word_index) + 1,activation='softmax') # 출력 층\n",
    "])\n",
    "# 모델 컴파일 및 학습\n",
    "gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru_model.fit(X, y, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seed_text, next_words, max_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_len - 1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                seed_text += \" \" + word\n",
    "                break\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성 예제\n",
    "seed_text = \"나는 내일\"\n",
    "print(\"RNN 생성 결과:\", generate_text(rnn_model, tokenizer, seed_text, next_words=5, max_len=max_len))\n",
    "print(\"LSTM 생성 결과:\", generate_text(lstm_model, tokenizer, seed_text, next_words=5, max_len=max_len))\n",
    "print(\"GRU 생성 결과:\", generate_text(gru_model, tokenizer, seed_text, next_words=5, max_len=max_len))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
